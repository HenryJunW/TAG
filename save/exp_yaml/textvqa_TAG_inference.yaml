dataset_attributes:
  m4c_textvqa:
    data_root_dir: ../data
    fast_read: False
    features_max_len: 100
    image_depth_first: False
    image_features:
      test:
      - feat_resx/test,ocr_feat_resx/textvqa_conf/test_images
      train:
      - feat_resx/train,ocr_feat_resx/textvqa_conf/train_images
      val:
      - feat_resx/train,ocr_feat_resx/textvqa_conf/train_images
    imdb_files:
      test:
      - imdb/m4c_textvqa/imdb_test_ocr_en.npy
      train:
      - imdb/m4c_textvqa/imdb_train_ocr_en.npy
      val:
#      during val. for augment the training dataset
      - imdb/m4c_textvqa/imdb_train_ocr_en.npy
    pretrain: False
    use_qag: True
    generate_aug_training: True
    processors:
      answer_processor:
        params:
          context_preprocessor:
            params:
              
            type: simple_word
          max_copy_steps: 30
          max_length: 100
          num_answers: 10
          preprocessor:
            params:
              
            type: simple_word
          vocab_file: m4c_vocabs/textvqa/fixed_answer_vocab_textvqa_5k.txt
        type: m4c_answer
      bbox_processor:
        params:
          max_length: 100
        type: bbox
      context_processor:
        params:
          max_length: 100
          model_file: .vector_cache/wiki.en.bin
        type: fasttext
      copy_processor:
        params:
          max_length: 100
          obj_max_length: 100
        type: copy
      ocr_token_processor:
        params:
          
        type: simple_word
      phoc_processor:
        params:
          max_length: 100
        type: phoc
      text_processor:
        params:
          max_length: 20
        type: bert_tokenizer
    return_info: True
    use_ocr: True
    use_ocr_info: True
datasets: m4c_textvqa
log_foldername: m4c_textvqa_m4c_split_13
model: m4c_split
model_attributes:
  m4c_split:
    classifier:
      ocr_max_num: 100
      ocr_ptr_net:
        hidden_size: 768
        query_key_size: 768
      params: {}
        
      type: linear
    losses:
    - type: m4c_decoding_bce_with_mask
    lr_scale_frcn: 0.1
    lr_scale_mmt: 1.0
    lr_scale_text_bert: 0.1
    metrics:
    - type: textvqa_accuracy
    mmt:
      hidden_size: 768
      num_hidden_layers: 4
    model: m4c_split
    model_data_dir: ../data
    obj:
      dropout_prob: 0.1
      mmt_in_dim: 2048
#      remove_obj_semantics: True
#      remove_obj_bbox: True
    ocr:
      dropout_prob: 0.1
      mmt_in_dim: 3052
#      remove_ocr_semantics: True
#      remove_ocr_bbox: True
    pretrain: False
    text_bert:
      num_hidden_layers: 0
    text_bert_init_from_bert_base: True
optimizer_attributes:
  params:
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
  type: Adam
training_parameters:
  batch_size: 128
  clip_gradients: True
  clip_norm_mode: all
  data_parallel: False
  dataset_size_proportional_sampling: True
  device: cuda
  distributed: True
#  TAG generate for the augmented training dataset
  evalai_inference: True
  save_aug_imdb_path: aug_imdb_train_ocr_en_largest_ocr_bbox

  experiment_name: run
  load_pretrained: False
  local_rank: 0
  log_dir: ./logs
  log_interval: 100
  logger_level: info
  lr_ratio: 0.1
  lr_scheduler: True
  lr_steps:
  - 28000
  - 38000
  max_epochs: None
  max_grad_l2_norm: 0.25
  max_iterations: 48000
  metric_minimize: False
  monitored_metric: m4c_textvqa/textvqa_accuracy
  num_workers: 4
  patience: 4000
  pin_memory: False
  pretrained_mapping:
    
  resume: False
  resume_file: None
  run_type: train+inference
  save_dir: save/m4c_split_refine_resx
  seed: 13
  should_early_stop: False
  should_not_log: False
  snapshot_interval: 1000
  task_size_proportional_sampling: True
  trainer: base_trainer
  use_warmup: True
  verbose_dump: False
  warmup_factor: 0.2
  warmup_iterations: 1000
